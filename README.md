# Sakata Index

The Sakata Index is a technical indicator calculated using a neural network designed for the Nikkei 225. Here's the format of the output log file:

- **Date**: This is the label for the date.
- **Prediction**: A value generated by a neural network model that attempts to predict the opening value of the N225 ETF.
- **Actual**: The actual opening value of the N225 ETF, which serves as the "teacher signal" for the neural network's predictions.
- **Difference**: The difference by subtracting the predicted value from the actual value.
- **Accumulator**: A running total of the daily differences.

The Sakata Index is a value that is normalized by the most recent 'Accumulator' for each period. The signal becomes strong to buy as the Sakata Index approaches 0; conversely, the signal becomes strong to sell as it approaches 100. Finally, this program's goal is calculating the Sakata index.  

The important aspect of the Sakata index is not bringing 'Prediction' close to 'Actual', but accumulating the difference obtained by subtracting 'Prediction' from 'Actual'. When this accumulated error reaches a certain threshold, it triggers a strong trading signal.  

The Sakata Index is not a universal indicator and is weak in identifying trends. When the Nikkei 225 continues to rise, it stays above 80, and when it continues to fall, it stays below 20. In such cases, above 80 does not necessarily mean a sell, and below 20 does not necessarily mean a buy. Additionally, it often exhibits similar characteristics to the RSI.  

# Result

- `output1.log`  
  This is a log of the results obtained by using a custom-implemented neural network to learn market data from approximately six months ago to today, segmented into 44-day intervals and learned day by day. The value of Norm: for each period corresponds to the Sakata Index. The training parameters are as described above.
  - Input: 3 layers (including bias)
  - Hidden: 4 layers (including bias)
  - Output: 1 layer
  - Initial weight: 0.5
  - Maximum training iterations: 500000
  - Activation function: Sigmoid
  - Loss function: least-squares method
  - Learning rate: 0.5
  - Biases: -1
  - Training data: The same dataset is used for both training and testing the model.

- `output2.log`  
  This is a log of the results obtained by using brain.js to learn market data from approximately six months ago to today, segmented into 44-day intervals and learned day by day. The value of Norm: for each period corresponds to the Sakata Index. The training parameters is same output1.log.

- `output3.log`  
  This is a log of the results obtained by using TensorFlow to learn market data from approximately six months ago to today, segmented into 44-day intervals and learned day by day. The value of Norm: for each period corresponds to the Sakata Index. The training parameters are as follows:
  - Input: 2 layers
  - Hidden: 16 layers
  - Output: 1 layer
  - Optimization: Adam
  - Initial weight: 0.5
  - Maximum training iterations: 1000
  - Activation function: Sigmoid
  - Learning rate: 0.001

- `plot-triple.png`  
  An image that combines the logs from `output1.log`, `output2.log`, and `output3.log` into a single line graph.
  When the three log files are trained over the same period, the following command will output a line graph.  
  `npm run plot-triple`
![plot-triple.png](https://raw.githubusercontent.com/BEROCHLU/sakata/main/result/plot-triple.png "The Sakata Index")

# Usage

To use this program, follow these steps:

1. **Install prerequisites**:
   - Python 3
   - Node.js 20

2. **Install packages**:
   - `pip install -r requirements.txt`
   - `npm install --omit=optional`

3. **Run scripts**:
   - `npm run getdata`  
   Get latest data.
   - `npm run cooking`  
   Normalize raw data and split by batch size.
   - `npm run output1`  
   To run mainb.js and append the results.
   - `npm run plot-output1`  
   To visualize the results.

**Optional install**
   - [brain.js](https://github.com/BrainJS/brain.js): A GPU accelerated library for Neural Networks written in JavaScript.
      - ###### on Linux
         1. `sudo apt-get install -y build-essential libglew-dev libglu1-mesa-dev libxi-dev pkg-config` 
         2. `npm install --include=optional --no-audit`
            - On a Raspberry Pi 4, it takes approximately 12 minutes.
         3. `npm run cooking`
         4. `npm run output2`
         5. `npm run plot-output2`
      - ###### on Windows
         1. Install [Visual Studio 2022](https://visualstudio.microsoft.com/downloads) or later.
         2. Install `Desktop development with C++` workload from Visual Studio Community.
         3. `npm install --include=optional --no-audit`
         4. `npm run cooking`
         5. `npm run output2`
         6. `npm run plot-output2`
      - #### If you can't install brain.js on Ubuntu 22 linux-x64 due to node-gyp ERR, downgrade the Node.js version to 16.20.2.

   - [TensorFlow](https://www.tensorflow.org): For users who need TensorFlow for Python-based neural network operations.
      - ###### on Linux
         1. `pip install requirements-t.txt`
            - On Raspberry Pi OS, type the following command to install h5py before installing TensorFlow:  
            `sudo apt-get install libhdf5-dev`
         2. `chmod 755 run_Linux.sh`
         3. `./run_Linux.sh`
      - ###### on Windows
         1. `pip install requirements-t.txt`
         2. `./run_Windows.ps1`

**Validation**
   - MinGW-w64: For users who want to validate using GCC with MinGW.  
      [This link](https://code.visualstudio.com/docs/cpp/config-mingw) is provided for setting up MinGW. However, due to an error with "The file has been downloaded incorrectly" [another link](https://winlibs.com/) is recommended.  
      1. rename `hdatexyt.csv` to `datexyt.csv`
      2. delete header in csv
      3. `gcc -O2 ./valid/cdevice.c -lm` 
      4. `a.exe` or `./a.out`  

# Note

Despite its vulnerabilities, Node.js 16 is chosen for its high speed on GitHub Actions. In my original neural network (main.js), I improved the speed of dot product calculations by replacing the 'dot' function from mathjs with the standard 'reduce' function. Consequently, the learning speed is now faster compared to brain.js.
